{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Opdracht\n",
    "Bij deze opdracht maken we gebruik van de library keras; misschien moet je die nog even pip installen. Verder gebruiken we een aantal beschrijvingen van kanker die we van deze site hebben gedownload. De beschrijvingen kun je hier vinden. Het stappenplan staat hier onder:\n",
    "\n",
    "1. laad de data in één lange string\n",
    "2. preprocess de data\n",
    "3. maak de vectoren x en de y en one-hot-encode deze\n",
    "4. maak en train het model\n",
    "5. maak een methode die op basis van een seed een nieuwe sequentie genereert"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T22:37:38.472935Z",
     "start_time": "2024-12-05T22:35:21.599493Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from keras.api.models import Sequential\n",
    "from keras.api.layers import LSTM, Dense, Embedding\n",
    "\n",
    "# Preprocess de zinnen\n",
    "def preprocess_sentence(sentence):\n",
    "    to_exclude = \"/.%-,'\\\":;()[]0123456789\"\n",
    "    sentence = \"\".join([char if char not in to_exclude else \" \" for char in sentence])\n",
    "    sentence = \" \".join([word for word in sentence.split() if word.lower() not in stopwoorden])\n",
    "    return sentence\n",
    "\n",
    "# Maak CBOW-pairen\n",
    "def create_pairs(corpus, sequence_length):\n",
    "    X, y = [], []\n",
    "    for sentence in corpus:\n",
    "        words = list(sentence)  # Splits de zin in karakters\n",
    "        for i in range(len(words) - sequence_length):\n",
    "            X.append(words[i:i + sequence_length])  # Context (input)\n",
    "            y.append(words[i + sequence_length])   # Target (output)\n",
    "    return X, y\n",
    "\n",
    "# Laad en preprocess data\n",
    "with open(\"wiki.txt\", \"r\") as file:\n",
    "    wiki_text = [line.strip() for line in file if len(line.strip().split()) >= 10]\n",
    "\n",
    "with open(\"stopwoorden.txt\", \"r\") as file:\n",
    "    stopwoorden = [line.strip() for line in file if line]\n",
    "\n",
    "# Combineer de data tot één string en preprocess\n",
    "processed_sentences = [preprocess_sentence(sentence) for sentence in wiki_text]\n",
    "text = \" \".join(processed_sentences)\n",
    "\n",
    "# Unieke karakters en mapping\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "# Maak CBOW-pairen (context en target)\n",
    "sequence_length = 40  # Lengte van de inputsequentie\n",
    "X, y = create_pairs([text], sequence_length)\n",
    "\n",
    "# One-hot-encode de data\n",
    "X_encoded = np.zeros((len(X), sequence_length, len(chars)), dtype=np.bool_)\n",
    "y_encoded = np.zeros((len(y), len(chars)), dtype=np.bool_)\n",
    "\n",
    "for i, sequence in enumerate(X):\n",
    "    for t, char in enumerate(sequence):\n",
    "        X_encoded[i, t, char_to_idx[char]] = 1\n",
    "    y_encoded[i, char_to_idx[y[i]]] = 1\n",
    "\n",
    "# Model maken\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(sequence_length, len(chars))),\n",
    "    Dense(len(chars), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train het model\n",
    "model.fit(X_encoded, y_encoded, batch_size=64, epochs=20)\n",
    "\n",
    "# Methode om een nieuwe sequentie te genereren\n",
    "def generate_sequence(seed, length=200):\n",
    "    result = seed\n",
    "    input_sequence = np.zeros((1, sequence_length, len(chars)), dtype=np.bool_)\n",
    "    \n",
    "    for t, char in enumerate(seed):\n",
    "        input_sequence[0, t, char_to_idx[char]] = 1\n",
    "\n",
    "    for _ in range(length):\n",
    "        prediction = model.predict(input_sequence, verbose=0)\n",
    "        next_char_idx = np.argmax(prediction)\n",
    "        next_char = idx_to_char[next_char_idx]\n",
    "        result += next_char\n",
    "\n",
    "        # Schuif het input window\n",
    "        input_sequence = np.roll(input_sequence, -1, axis=1)\n",
    "        input_sequence[0, -1, :] = 0\n",
    "        input_sequence[0, -1, next_char_idx] = 1\n",
    "\n",
    "    return result\n",
    "\n",
    "# Test sequentie genereren\n",
    "seed_text = text[:sequence_length]\n",
    "generated_sequence = generate_sequence(seed_text)\n",
    "print(\"Generated sequence:\", generated_sequence)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 23:35:21.879535: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 23:35:21.883284: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-12-05 23:35:21.893906: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733438121.914985    2448 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733438121.921437    2448 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 23:35:21.944396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1733438125.003990    2448 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/home/mage/Documents/ModellerenVanKanker/.venv/lib/python3.11/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "2024-12-05 23:35:25.116493: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 25634880 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 31ms/step - accuracy: 0.1568 - loss: 3.2105\n",
      "Epoch 2/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.2061 - loss: 2.8602\n",
      "Epoch 3/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.2535 - loss: 2.6355\n",
      "Epoch 4/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.2678 - loss: 2.5049\n",
      "Epoch 5/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.2939 - loss: 2.3828\n",
      "Epoch 6/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.3234 - loss: 2.2852\n",
      "Epoch 7/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.3392 - loss: 2.2453\n",
      "Epoch 8/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 35ms/step - accuracy: 0.3589 - loss: 2.1781\n",
      "Epoch 9/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.3771 - loss: 2.1251\n",
      "Epoch 10/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.3851 - loss: 2.0818\n",
      "Epoch 11/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.3963 - loss: 2.0456\n",
      "Epoch 12/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 32ms/step - accuracy: 0.4042 - loss: 1.9974\n",
      "Epoch 13/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 33ms/step - accuracy: 0.4174 - loss: 1.9687\n",
      "Epoch 14/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4291 - loss: 1.9266\n",
      "Epoch 15/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4382 - loss: 1.8960\n",
      "Epoch 16/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4450 - loss: 1.8688\n",
      "Epoch 17/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 30ms/step - accuracy: 0.4541 - loss: 1.8593\n",
      "Epoch 18/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4667 - loss: 1.8112\n",
      "Epoch 19/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4609 - loss: 1.8235\n",
      "Epoch 20/20\n",
      "\u001B[1m186/186\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 31ms/step - accuracy: 0.4868 - loss: 1.7582\n",
      "Generated sequence: Kanker medisch Latijn neoplasma malignumen mutaties veronen mutatie beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beelde beel\n"
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modelleren_van_kanker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
